{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz #0801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Text Classification with Keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\latitude\\anaconda3\\lib\\site-packages (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following question by providing Python code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). Read in the movie review data from Cornell CS department. Carry out the EDA. <br>\n",
    "- The data can be found [here](https://www.cs.cornell.edu/people/pabo/movie-review-data). <br>\n",
    "- Download the “polarity dataset” and unzip. <br>\n",
    "- Under the \"txt_sentoken” folder, there are “pos” and “neg\" subfolders. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = load_files('txt_sentoken/')\n",
    "X, y = reviews.data, reviews.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([1000, 1000], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y).set_title(\"Frequency Table\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2). Carry out the data preprocessing: <br>\n",
    "- Cleaning.\n",
    "- Stopword removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Latitude\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Latitude\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "documents = []\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "for sen in range(0, len(my_docs)):\n",
    "     # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(my_docs[sen]))\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arnold schwarzenegger ha been an icon for action enthusiast since the late 80 but lately his film have been very sloppy and the one liner are getting worse nit hard seeing arnold a mr freeze in batman and robin especially when he say ton of ice joke but hey he got 15 million what it matter to him nonce again arnold ha signed to do another expensive blockbuster that can compare with the like of the terminator series true lie and even eraser nin this so called dark thriller the devil gabriel byrne ha come upon earth to impregnate woman robin tunney which happens every 1000 year and basically destroy the world but apparently god ha chosen one man and that one man is jericho cane arnold himself nwith the help of trusty sidekick kevin pollack they will stop at nothing to let the devil take over the world nparts of this are actually so absurd that they would fit right in with dogma nyes the film is that weak but it better than the other blockbuster right now sleepy hollow but it make the world is not enough look like 4 star film nanyway this definitely doesn seem like an arnold movie nit just wasn the type of film you can see him doing nsure he gave u few chuckle with his well known one liner but he seemed confused a to where his character and the film wa going nit understandable especially when the ending had to be changed according to some source naside form that he still walked through it much like he ha in the past few film ni sorry to say this arnold but maybe these are the end of your action day nspeaking of action where wa it in this film nthere wa hardly any explosion or fight nthe devil made few place explode but arnold wasn kicking some devil butt nthe ending wa changed to make it more spiritual which undoubtedly ruined the film ni wa at least hoping for cool ending if nothing else occurred but once again wa let down ni also don know why the film took so long and cost so much nthere wa really no super affect at all unless you consider an invisible devil who wa in it for 5 minute top worth the overpriced budget nthe budget should have gone into better script where at least audience could be somewhat entertained instead of facing boredom nit pitiful to see how script like these get bought and made into movie ndo they even read these thing anymore nit sure doesn seem like it nthankfully gabriel performance gave some light to this poor film nwhen he walk down the street searching for robin tunney you can help but feel that he looked like devil nthe guy is creepy looking anyway nwhen it all over you re just glad it the end of the movie ndon bother to see this if you re expecting solid action flick because it neither solid nor doe it have action nit just another movie that we are suckered in to seeing due to strategic marketing campaign nsave your money and see the world is not enough for an entertaining experience\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3). Carry out label encoding by integers (required form by Keras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>arnold schwarzenegger ha been an icon for acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>good film are hard to find these day ngreat fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>quaid star a man who ha taken up the proffesio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>we could paraphrase michelle pfieffer characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>kolya is one of the richest film ve seen in so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  arnold schwarzenegger ha been an icon for acti...\n",
       "1       1  good film are hard to find these day ngreat fi...\n",
       "2       1  quaid star a man who ha taken up the proffesio...\n",
       "3       0  we could paraphrase michelle pfieffer characte...\n",
       "4       1  kolya is one of the richest film ve seen in so..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = {'target': y.tolist(), 'text': documents}\n",
    "df = pd.DataFrame(A)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4). Prepare the data for AI: <br>\n",
    "- Apply the padding.\n",
    "- Split the data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "\n",
    "# split our data into train set (80%) and test set (20%)\n",
    "train_data, test_data = train_test_split(df, test_size = 1 - train_size, random_state = 0, stratify = df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  1600\n",
      "Test data size:  400\n",
      "Train data distr:\n",
      " 1    800\n",
      "0    800\n",
      "Name: target, dtype: int64\n",
      "Test data distr:\n",
      " 1    200\n",
      "0    200\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# length of each set\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))\n",
    "\n",
    "# how many examples of each class there is in each set\n",
    "print(\"Train data distr:\\n\", train_data.target.value_counts())\n",
    "print(\"Test data distr:\\n\", test_data.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "#The above script divides data into 20% test set and 80% training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer in the train text\n",
    "tokenizer.fit_on_texts(train_data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# get max length of the train data\n",
    "max_length = max([len(s.split()) for s in train_data.text])\n",
    "# pad sequences in x_train data set to the max length\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.text),maxlen = max_length)\n",
    "# pad sequences in x_test data set to the max length\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.text),maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (1600, 2305)\n",
      "x_test shape:  (400, 2305)\n",
      "y_train shape: (1600, 1)\n",
      "y_test shape: (400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5). Define the AI model (Embedding + LSTM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6). Define the optimizer and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit(x_train, y_train, epochs = 100, batch_size = 16, shuffle=True, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7). Train the model and visualize the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 2305), (1600, 1))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 50)           14535700  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 200)               200800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,749,429\n",
      "Trainable params: 14,749,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(290714, 50, input_length=100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200, dropout = 0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "epochs = 15\n",
    "batch_size = 1024\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs,batch_size=batch_size,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8). Display the test result (accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_test, y_test, batch_size = BATCH_SIZE)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
